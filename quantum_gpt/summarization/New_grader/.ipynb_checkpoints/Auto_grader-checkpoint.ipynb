{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088faec5-fc09-4cf4-9c12-a785ca813b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file at auto_graded_GPT4.json was not found.\n",
      "7\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 2}\n",
      "6\n",
      "The student's response contains some correct logic but also has significant errors. The student correctly identifies that the spin states along the z-axis can be represented in the x-basis and that half of the spins measured along the x-axis at t1 would be discarded. However, the student incorrectly states that for particles measured along the z-axis at t1, the fraction that remains in the saved subensemble is P_{+z} = 1. The correct answer is that the fraction is 0.5 for both measurements along the z and x axes. This is a major error in the conclusion, resulting in a deduction of 3 points. The student also introduces a potential hallucination by discussing experimental uncertainties and interactions between particles, which are not relevant to the idealized question posed, leading to a deduction of 1 point. The logic used to arrive at the incorrect conclusion is flawed, but the student does correctly apply the concept of basis states and the idea of discarding half the spins measured along the x-axis, so only 2 points are deducted for logic mistakes. The final score is 6 out of 10.\n",
      "7\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 2}\n",
      "7\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 2}\n",
      "7\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 2}\n",
      "10\n",
      "The student's response correctly identifies the probabilities for each step of the measurement process and accurately calculates the joint probability P_{+b+c} as well as the total probability P_{+c}. The student then correctly computes the fraction of particles with spin up along 'b' in the first measurement among those with spin up along 'c' in the second measurement, which is the question's requirement. The logic and reasoning behind the calculations are sound, and there are no hallucinated points or errors in the conclusion. Therefore, the student's response earns 3 points for the correct conclusion, 4 points for logic and reasoning, and 3 points for the absence of hallucinations, totaling a full score of 10.\n",
      "6\n",
      "The student's response does not directly answer the question about the fraction of particles with spin up along b in the first measurement, but instead discusses the general principles of quantum measurement and the need for specific information about the angles. The student correctly states that the act of measurement in quantum mechanics is intrusive and influences the system, which is a valid point. However, the student fails to apply the given formulas to calculate the fraction, which is a significant logic mistake. The student correctly identifies that probabilities can be calculated if the angles are known, but does not use the provided step-by-step ground truth to reach a conclusion. There are no hallucinated points in the response, but the student's failure to use the provided formulas and to calculate the fraction results in a deduction of points for logic and reasoning. The conclusion is also incorrect as it is possible to calculate the fraction with the given information, leading to a deduction in points for the conclusion as well.\n",
      "7\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 2}\n",
      "7\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 2}\n",
      "7\n",
      "{'conclusion': 3, 'logic and reasoning': 2, 'potential hallucinations': 2}\n",
      "6\n",
      "{'conclusion': 3, 'logic_and_reasoning': 2, 'potential_hallucinations': 1}\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for gpt-4-1106-preview in organization org-2egVDqMKbOs6gqZCWDkQQUmT on tokens per min. Limit: 10000 / min. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m     graded_quiz_hints \u001b[38;5;241m=\u001b[39m read_json_file(input_json_file_path)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Shuffle the hints, grade them, and collect the rationales\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[43mgrade_individual_hints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraded_quiz_hints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrading complete. All items have been saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mgrade_individual_hints\u001b[0;34m(quiz_data, graded_data_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m student_response \u001b[38;5;241m=\u001b[39m item[key]\n\u001b[1;32m     19\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-1106-preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250;43m                \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43;03m                You are the grader for a quantum physics class. \u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43;03m    Your job is to grade the response of the students given a question.\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43;03m    You will be provided with the question, student response, and ground truth answer.\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43;03m    You must grade the response base on the criteria (3 points to conclusion (deducted if wrong),4 points to logic and reasoning (minus 2 points for each logic mistake), and 3 points to potential halluciantions (minus 1 for each hallucinated point)) \u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43;03m    Assign a score within the range of 1 to 10. Generate scoring output in pure json format with two fields, score and rationale.\\\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;43;03m                \"\"\"\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTreat the following as ground truch: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mground_truth\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe question is \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m. The student response is \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mstudent_response\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#        {\"role\": \"assistant\", \"content\": \u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#         \"\"\"\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#         Here are some facts, treat these as ground truth when grading the response. {ground_truth}\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#         \"\"\"}\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m response_str\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     43\u001b[0m response_return\u001b[38;5;241m.\u001b[39mappend(response_str)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for gpt-4-1106-preview in organization org-2egVDqMKbOs6gqZCWDkQQUmT on tokens per min. Limit: 10000 / min. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import openai\n",
    "import time\n",
    "import os\n",
    "openai.api_key = \"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\"\n",
    "response_return=[]\n",
    "def grade_individual_hints(quiz_data, graded_data_path):\n",
    "    for item_index, item in enumerate(quiz_data):\n",
    "        \n",
    "        # Extract keys and shuffle them without losing the correlation\n",
    "        hint_keys = ['No_hint', 'Hint1', 'Hint2', 'Hint3']\n",
    "        random.shuffle(hint_keys)\n",
    "\n",
    "        # Print out each hint for grading\n",
    "        for key in hint_keys:\n",
    "            question = item['question']\n",
    "            student_response = item[key]\n",
    "            ground_truth = item['answer']\n",
    "            response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-4-1106-preview\",\n",
    "                        temperature=0.2,\n",
    "                        max_tokens=800,\n",
    "                        response_format={ \"type\": \"json_object\" },\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \n",
    "                            \"\"\"\n",
    "                            You are the grader for a quantum physics class. \n",
    "                Your job is to grade the response of the students given a question.\n",
    "                You will be provided with the question, student response, and ground truth answer.\n",
    "                You must grade the response base on the criteria (3 points to conclusion (deducted if wrong),4 points to logic and reasoning (minus 2 points for each logic mistake), and 3 points to potential halluciantions (minus 1 for each hallucinated point)) \n",
    "                Assign a score within the range of 1 to 10. Generate scoring output in pure json format with two fields, score and rationale.\\\n",
    "                            \"\"\"}, \n",
    "                            {\"role\": \"assistant\", \"content\": \"Treat the following as ground truch: \"+ground_truth},\n",
    "                            {\"role\": \"user\", \"content\": \"The question is \"+question+\". The student response is \"+student_response}, \n",
    "                    #        {\"role\": \"assistant\", \"content\": \n",
    "                    #         \"\"\"\n",
    "                    #         Here are some facts, treat these as ground truth when grading the response. {ground_truth}\n",
    "                    #         \"\"\"}\n",
    "                            ],\n",
    "                    )\n",
    "            response_str=response.choices[0].message.content\n",
    "            response_return.append(response_str)\n",
    "            try:\n",
    "                # Attempt to parse the JSON content\n",
    "                parsed_json = json.loads(response_str)\n",
    "            \n",
    "                # Extract the relevant information\n",
    "                grade = parsed_json.get('score')\n",
    "                rationale = parsed_json.get('rationale')\n",
    "                print(grade)\n",
    "                print(rationale)\n",
    "                \n",
    "                # Store the grade and rationale in the item\n",
    "                item[key] = {'content': item[key], 'grade': grade, 'rationale': rationale}\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "            \n",
    "        # Save the graded item to the file\n",
    "        save_progress(quiz_data, 'auto_graded_GPT4.json')\n",
    "        time.sleep(60)\n",
    "        \n",
    "def save_progress(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def read_json_file(filepath):\n",
    "    \"\"\"\n",
    "    This function reads a JSON file from the given filepath and returns the data.\n",
    "    If the file is not found, is not a valid JSON, or another error occurs,\n",
    "    it will handle the exception and return None.\n",
    "\n",
    "    :param filepath: The path to the JSON file to be read.\n",
    "    :return: Parsed JSON data or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {filepath} was not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file at {filepath} is not a valid JSON file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    return None\n",
    "\n",
    "# Path to the input and output JSON files\n",
    "input_json_file_path = 'GPT4_results_wq.json'\n",
    "output_json_file_path = 'auto_graded_GPT4.json'\n",
    "\n",
    "# Load existing data if available, else load the original quiz hints\n",
    "graded_quiz_hints = read_json_file(output_json_file_path)\n",
    "if not graded_quiz_hints:\n",
    "    graded_quiz_hints = read_json_file(input_json_file_path)\n",
    "\n",
    "# Shuffle the hints, grade them, and collect the rationales\n",
    "grade_individual_hints(graded_quiz_hints, output_json_file_path)\n",
    "\n",
    "print(\"Grading complete. All items have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6c55f-fdc6-461e-9489-cf9984d6b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e875df7-efa3-4b5f-ab31-a136d3c8ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auto_graded_GPT4.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(response_return, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bb7bf-fe97-49e9-86f8-0a914c85224e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
